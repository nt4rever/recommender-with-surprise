{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import Dataset, SVD, Reader, accuracy\n",
    "from surprise.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>314</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>439</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>588</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1169</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1185</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id  user_id  rating\n",
       "0        1      314       5\n",
       "1        1      439       3\n",
       "2        1      588       5\n",
       "3        1     1169       4\n",
       "4        1     1185       4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_data = pd.read_csv('./dataset/ratings.csv')\n",
    "ratings_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# book ratings range from 1 star -> 5 stars\n",
    "# explicit rating\n",
    "reader = Reader(rating_scale=(1, 5)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.load_from_df(ratings_data[['user_id', 'book_id', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(data, test_size=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate default: lr_all = 0.005, regularization terms: reg_all = 0.02\n",
    "model = SVD(random_state=0, n_factors=100, n_epochs=30, verbose=True,lr_all=0.005, reg_all=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "Processing epoch 20\n",
      "Processing epoch 21\n",
      "Processing epoch 22\n",
      "Processing epoch 23\n",
      "Processing epoch 24\n",
      "Processing epoch 25\n",
      "Processing epoch 26\n",
      "Processing epoch 27\n",
      "Processing epoch 28\n",
      "Processing epoch 29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x1d6503ba040>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 8836       item: 8472       r_ui = 5.00   est = 4.21   {'was_impossible': False}\n",
      "user: 47730      item: 5737       r_ui = 4.00   est = 3.32   {'was_impossible': False}\n",
      "user: 45313      item: 4710       r_ui = 5.00   est = 3.65   {'was_impossible': False}\n",
      "user: 34535      item: 4056       r_ui = 3.00   est = 3.82   {'was_impossible': False}\n",
      "user: 19271      item: 8313       r_ui = 3.00   est = 4.15   {'was_impossible': False}\n",
      "user: 42284      item: 4735       r_ui = 5.00   est = 3.51   {'was_impossible': False}\n",
      "user: 14839      item: 4537       r_ui = 5.00   est = 3.75   {'was_impossible': False}\n",
      "user: 38663      item: 7292       r_ui = 2.00   est = 3.25   {'was_impossible': False}\n",
      "user: 27780      item: 8027       r_ui = 4.00   est = 4.44   {'was_impossible': False}\n",
      "user: 8233       item: 8077       r_ui = 4.00   est = 3.85   {'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "test_predictions = model.test(test_set)\n",
    "for i in range(10):\n",
    "    print(test_predictions[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE (Root Mean Squared Error), computed as:\n",
    "\n",
    "$$\\sqrt{\\frac{1}{N} \\sum(\\hat{r_{ui}} - r_{ui})^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8488\n"
     ]
    }
   ],
   "source": [
    "#model evaluation\n",
    "rmse = accuracy.rmse(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE score: 0.8484454801491901\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "param_grid = {'n_epochs': [25, 30], 'lr_all': [0.002, 0.005]}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3)\n",
    "gs.fit(data)\n",
    "print('Best RMSE score:', gs.best_score['rmse'])\n",
    "print('Best parameters:', gs.best_params['rmse'])\n",
    "# Best RMSE score: 0.8484454801491901\n",
    "# Best parameters: {'n_epochs': 25, 'lr_all': 0.005}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Best RMSE score: 0.8484454801491901\n",
    "- Best parameters: {'n_epochs': 25, 'lr_all': 0.005}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "Processing epoch 20\n",
      "Processing epoch 21\n",
      "Processing epoch 22\n",
      "Processing epoch 23\n",
      "Processing epoch 24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x1d6503ba730>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = SVD(random_state=0, n_factors=100, n_epochs=25, lr_all=0.005, verbose=True)\n",
    "best_model.fit(data.build_full_trainset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import dump\n",
    "\n",
    "# Save model\n",
    "file_path = 'store/surprise_model.dump'\n",
    "dump.dump(file_path, algo=best_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Surprise/SVD\n",
    "\n",
    "The SVD model algorithm is very similar to the ALS algorithm presented in the ALS deep dive notebook. The two differences between the two approaches are:\n",
    "\n",
    "- SVD additionally models the user and item biases (also called baselines in the litterature) from users and items.\n",
    "- The optimization technique in ALS is Alternating Least Squares (hence the name), while SVD uses stochastic gradient descent.\n",
    "\n",
    "### 1.1 The SVD model\n",
    "\n",
    "SVD introduces two new scalar variables: the user biases $b_u$ and the item biases $b_i$. The user biases are supposed to capture the tendency of some users to rate items higher (or lower) than the average. The same goes for items: some items are usually rated higher than some others. The model is SVD is then as follows:\n",
    "\n",
    "$$\\hat r_{u,i} = \\mu + b_u + b_i + q_{i}^{T}p_{u}$$\n",
    "\n",
    "Where $\\mu$ is the global average of all the ratings in the dataset. The regularised optimization problem naturally becomes:\n",
    "\n",
    "$$ \\sum(r_{u,i} - (\\mu + b_u + b_i + q_{i}^{T}p_{u}))^2 +     \\lambda(b_i^2 + b_u^2 + ||q_i||^2 + ||p_u||^2)$$\n",
    "\n",
    "where $\\lambda$ is a the regularization parameter.\n",
    "\n",
    "\n",
    "### 1.2 Stochastic Gradient Descent\n",
    "\n",
    "Stochastic Gradient Descent (SGD) is a very common algorithm for optimization where the parameters (here the biases and the factor vectors) are iteratively incremented with the negative gradients w.r.t the optimization function. The algorithm essentially performs the following steps for a given number of iterations:\n",
    "\n",
    "\n",
    "$$b_u \\leftarrow b_u + \\gamma (e_{ui} - \\lambda b_u)$$\n",
    "$$b_i \\leftarrow b_i + \\gamma (e_{ui} - \\lambda b_i)$$  \n",
    "$$p_u \\leftarrow p_u + \\gamma (e_{ui} \\cdot q_i - \\lambda p_u)$$\n",
    "$$q_i \\leftarrow q_i + \\gamma (e_{ui} \\cdot p_u - \\lambda q_i)$$\n",
    "\n",
    "where $\\gamma$ is the learning rate and $e_{ui} =  r_{ui} - \\hat r_{u,i} = r_{u,i} - (\\mu + b_u + b_i + q_{i}^{T}p_{u})$ is the error made by the model for the pair $(u, i)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Manual_SVD:\n",
    "    def __init__(self, n_factors=100, n_epochs=20, init_mean=0, init_std_dev=.1, lr_all=.005, reg_all=.02) -> None:\n",
    "        self.n_factors = n_factors\n",
    "        self.n_epochs = n_epochs\n",
    "        self.init_mean = init_mean\n",
    "        self.init_std_dev = init_std_dev\n",
    "        self.lr = lr_all\n",
    "        self.reg = reg_all\n",
    "\n",
    "    def fit(self, trainset):\n",
    "        self.sgd(trainset)\n",
    "        return self\n",
    "\n",
    "    def sgd(self, trainset):\n",
    "        # biased users\n",
    "        bu = np.zeros(trainset.n_users, dtype=np.double)\n",
    "        bi = np.zeros(trainset.n_items, dtype=np.double)\n",
    "\n",
    "        rng = np.random.RandomState(0)\n",
    "        # pu: m*k \n",
    "        pu = rng.normal(self.init_mean, self.init_std_dev,\n",
    "                        size=(trainset.n_users, self.n_factors))\n",
    "        #pi: n*k\n",
    "        qi = rng.normal(self.init_mean, self.init_std_dev,\n",
    "                        size=(trainset.n_items, self.n_factors))\n",
    "\n",
    "        lr = self.lr\n",
    "        reg = self.reg\n",
    "        n_factors = self.n_factors\n",
    "\n",
    "        global_mean = trainset.global_mean\n",
    "\n",
    "        for current_epoch in range(self.n_epochs):\n",
    "            print(\"Processing epoch {}\".format(current_epoch))\n",
    "            for u, i, r in trainset.all_ratings():\n",
    "                # compute current error\n",
    "                dot = 0  # <q_i, p_u>\n",
    "                for f in range(n_factors):\n",
    "                    dot += qi[i, f] * pu[u, f]\n",
    "                err = r - (global_mean + bu[u] + bi[i] + dot)\n",
    "\n",
    "                # update biases, SGD\n",
    "                bu[u] += lr * (err - reg * bu[u])\n",
    "                bi[i] += lr * (err - reg * bi[i])\n",
    "\n",
    "                # update factors\n",
    "                for f in range(n_factors):\n",
    "                    puf = pu[u, f]\n",
    "                    qif = qi[i, f]\n",
    "                    pu[u, f] += lr * (err * qif - reg * puf)\n",
    "                    qi[i, f] += lr * (err * puf - reg * qif)\n",
    "                    \n",
    "        self.bu = np.asarray(bu)\n",
    "        self.bi = np.asarray(bi)\n",
    "        self.pu = np.asarray(pu)\n",
    "        self.qi = np.asarray(qi)\n",
    "\n",
    "    def predict(self, u, i):\n",
    "        known_user = self.trainset.knows_user(u)\n",
    "        known_item = self.trainset.knows_item(i)\n",
    "\n",
    "        est = self.trainset.global_mean\n",
    "        if known_user:\n",
    "            est += self.bu[u]\n",
    "\n",
    "        if known_item:\n",
    "            est += self.bi[i]\n",
    "\n",
    "        if known_user and known_item:\n",
    "            est += np.dot(self.qi[i], self.pu[u])\n",
    "        return est"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "surprise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
